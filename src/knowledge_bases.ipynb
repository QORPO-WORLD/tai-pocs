{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from application.aws import AwsAPI\n",
    "from application.game import Game\n",
    "from application.utils import (\n",
    "    get_game_events,\n",
    "    dump_message_to_file,\n",
    "    generate_batch_sizes,\n",
    ")\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock knowledge bases test\n",
    "\n",
    "This is the same test as in `game_events_realistic.ipynb`, but game state data is stored inside the knowledge base instead of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_events = get_game_events(\"data/events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_prompt = lambda new_events_num: (\n",
    "    \"Imagine you're commenting the battle royale game match. \"\n",
    "    \"We have a knowledge base where we store information about the game events. \"\n",
    "    f\"Recently, {new_events_num} new events were added to the game.json file, you can decide either to comment on all of them or comment the last of them while also keeping in mind other events. \"\n",
    "    \"You're not supposed to always use each field for the comment, but you can use them if you think they're relevant. \"\n",
    "    \"Try to also remember previous events and if you see some patterns feel free to voice them. \"\n",
    "    \"Please comment on the recent events using 3 senteces max. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_sentences(new_events_num: int, aws: AwsAPI, model_id: str, temperature: float) -> Generator[str, None, None]:\n",
    "    model = aws.models_mapping[model_id]\n",
    "\n",
    "    yield from aws.get_streamed_response_rag(model, form_prompt(new_events_num), time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Nova Pro with Knowledge Base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [03:18<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. time per events batch: 3.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "game = Game(game_events)\n",
    "winner = game.create_players_tree()\n",
    "num_events_total = game.num_players_total - 1\n",
    "batch_sizes = generate_batch_sizes(num_events_total)\n",
    "\n",
    "\n",
    "def run_dialogue(model_id, region, temperature=0.9):\n",
    "    aws = AwsAPI(region)\n",
    "    events_nums = copy.copy(batch_sizes)\n",
    "    filename = f\"output/text/RAG/{int(time.time())}-{model_id}.txt\"\n",
    "\n",
    "    game.start()\n",
    "\n",
    "    elapsed_total, events_num, new_events_num = 0, 0, 0\n",
    "    game_state = []\n",
    "    for event in tqdm.tqdm(game.get_events(winner), total=num_events_total):\n",
    "        game_state.append(event)\n",
    "        if events_num < events_nums[-1]:\n",
    "            events_num += 1\n",
    "            continue\n",
    "        else:\n",
    "            new_events_num = events_num\n",
    "            events_nums.pop()\n",
    "            events_num = 1\n",
    "\n",
    "        start_time = time.time()\n",
    "        aws.update_knowledge_base(game_state)\n",
    "        \n",
    "        response = []\n",
    "        try:\n",
    "            for sentence in _get_sentences(new_events_num, aws, model_id, temperature):\n",
    "                response.append(sentence)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        elapsed_total += time.time() - start_time\n",
    "\n",
    "        dump_message_to_file(\"Assistant\", \"\".join(response), filename)\n",
    "\n",
    "    print(f\"Avg. time per events batch: {elapsed_total / len(batch_sizes):.2f}s\")\n",
    "\n",
    "\n",
    "print(\"Testing Nova Pro with Knowledge Base...\")\n",
    "run_dialogue(\"amazon.nova-pro-v1:0\", \"us-east-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
