{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "from application.aws import AwsAPI\n",
    "from application.game import Game\n",
    "from application.utils import get_kill_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realistic kill events test\n",
    "\n",
    "For this test, kill events were generated as close to real ones as possible: a tree structure was generated to map events to users, each user got 0 to 6 kills randomly assigned, tree was traversed from leaves to root, so that in the end only 1 user is alive. Context window size was set to 20 messages for performance reasons, so the model generates responses based on 9 previous events and the current event. Claude v2 was used, this notebook can be utilized to test other models' generations quality on that task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kills = get_kill_events(\"data/kills.csv\")\n",
    "game = Game(kills)\n",
    "aws = AwsAPI()\n",
    "root = game.create_users_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompts = [\n",
    "    (\n",
    "        \"Imagine you're commenting the battle royale game match. You'll be getting kill events from the game like this one: \"\n",
    "        '[{\"victim\": {\"username\": str},\"KillInstigator\": {\"username\": str,\"Distance\": float,\"first_kill\": bool,\"used_weapon\": {\"type\": str,\"name\": str},\"Headshot\": bool,\"OneShot\": bool,\"num_kills\": int,\"previous_victims\": [str]},\"location\": str,\"num_players_alive\": int}]. '\n",
    "        \"Sometimes you will be getting more than one event in this list. \"\n",
    "        \"You'll need to comment on the kill events, using 3 senteces max. \"\n",
    "        \"If there are multiple events, you can decide either to comment on all of them or comment the last of them while also keeping in mind other events. \"\n",
    "        \"Even if there are multiple events, you should still be able to say everything in 3 sentences. \"\n",
    "        \"You're not supposed to always use each field for the comment, but you can use them if you think they're relevant. \"\n",
    "        \"Try to also remember previous events and if you see some patterns feel free to voice them. Understood?\"\n",
    "    ),\n",
    "    \"Understood. I'm ready to commentate on the battle royale game events.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = deque(init_prompts)\n",
    "context_window_size = 20\n",
    "file_timestamp = int(time.time())\n",
    "with open(f\"output/text/{file_timestamp}-dialogue.txt\", \"a\") as f:\n",
    "    f.write(f\"User: {q[-2]}\\n\")\n",
    "    f.write(f\"Assistant: {q[-1]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_events: list[list[dict]] = []\n",
    "kill_events_flat = [kill_event for kill_event in game.get_kill_event(root)]\n",
    "i = 0\n",
    "while i < len(kill_events_flat):\n",
    "    kill_events.append([])\n",
    "    events_num = min(random.randint(1, 4), len(kill_events_flat) - i)\n",
    "    for _ in range(events_num):\n",
    "        kill_events[-1].append(kill_events_flat[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock latencies: avg=0.95sec, min=0.38sec, max=1.52sec\n",
      "Bedrock latencies: avg=0.69sec, min=0.30sec, max=1.19sec\n",
      "Bedrock latencies: avg=1.72sec, min=0.53sec, max=2.92sec\n",
      "Bedrock latencies: avg=1.68sec, min=0.53sec, max=2.84sec\n",
      "Bedrock latencies: avg=1.25sec, min=0.61sec, max=1.89sec\n",
      "Bedrock latencies: avg=1.70sec, min=0.68sec, max=2.71sec\n",
      "Bedrock latencies: avg=1.59sec, min=1.06sec, max=2.11sec\n",
      "Bedrock latencies: avg=1.77sec, min=1.15sec, max=2.39sec\n",
      "Bedrock latencies: avg=1.41sec, min=0.38sec, max=3.08sec\n",
      "Bedrock latencies: avg=2.23sec, min=1.00sec, max=3.46sec\n",
      "Bedrock latencies: avg=2.37sec, min=1.01sec, max=3.72sec\n",
      "Bedrock latencies: avg=1.48sec, min=0.78sec, max=2.59sec\n"
     ]
    }
   ],
   "source": [
    "for kill_events_list in kill_events:\n",
    "    if len(q) + 2 > context_window_size:\n",
    "        for _ in range(len(init_prompts)):\n",
    "            q.popleft()\n",
    "        q.popleft()\n",
    "        q.popleft()\n",
    "        for prompt in reversed(init_prompts):\n",
    "            q.appendleft(prompt)\n",
    "\n",
    "    q.append(json.dumps(kill_events_list))\n",
    "\n",
    "    roles = (\"user\", \"assistant\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": roles[i % 2],\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "        for i, prompt in enumerate(q)\n",
    "    ]\n",
    "    response = []\n",
    "    try:\n",
    "        for sentence in aws.get_streamed_response_claude(messages, time.time()):\n",
    "            response.append(sentence)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "    print(aws.get_bedrock_stats())\n",
    "\n",
    "    q.append(\"\".join(response))\n",
    "    \n",
    "    with open(f\"output/text/{file_timestamp}-dialogue.txt\", \"a\") as f:\n",
    "        f.write(f\"User: {q[-2]}\\n\")\n",
    "        f.write(f\"Assistant: {q[-1]}\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
