{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from application.aws import AwsAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency test depending on context size\n",
    "\n",
    "In this test, the model gets a list of messages which size increases on each iteration, and times to generate 1 sentence are measured (we measure 1 sentence as we have to pass the response to Polly and create an audio, and it works in the most efficient way if passed sentence by sentence). Here, Claude v2 was used to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws = AwsAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'victim': {'username': 'random_user0'}, 'KillInstigator': {'username': 'ProGamer69', 'Distance': 419.18713260946123, 'first_kill': True, 'used_weapon': {'type': 'Pistol', 'name': 'BerettaPistol'}, 'Headshot': False, 'OneShot': False}}\n"
     ]
    }
   ],
   "source": [
    "kills = []\n",
    "with open(\"data/kills.csv\") as f:\n",
    "    for line in f:\n",
    "        parts = line.split(\"\\t\")\n",
    "        kill_str = parts[2].replace('\"\"', '\"')\n",
    "        kill_str = kill_str[1:-1]\n",
    "        kill_json = json.loads(kill_str)\n",
    "        kills.append(kill_json)\n",
    "\n",
    "for i in range(len(kills)):\n",
    "    kills[i] = {\n",
    "        \"victim\": {\n",
    "            \"username\": f\"random_user{i}\",\n",
    "        },\n",
    "        \"KillInstigator\": {\n",
    "            \"username\": \"ProGamer69\",\n",
    "            \"Distance\": kills[i][\"KillInstigator\"][\"Distance\"],\n",
    "            \"first_kill\": bool(kills[i][\"KillInstigator\"].get(\"first_kill\", False)),\n",
    "            \"used_weapon\": {\n",
    "                \"type\": kills[i][\"KillInstigator\"][\"used_weapon\"][\"type\"],\n",
    "                \"name\": kills[i][\"KillInstigator\"][\"used_weapon\"][\"name\"],\n",
    "            },\n",
    "            \"Headshot\": bool(kills[i][\"KillInstigator\"][\"Headshot\"]),\n",
    "            \"OneShot\": bool(kills[i][\"KillInstigator\"][\"OneShot\"]),\n",
    "        }\n",
    "    }\n",
    "print(kills[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Imagine you're commenting the battle royale game match. You'll be getting kill events from the game like this one: \"\n",
    "    f\"{json.dumps(kills[0])}. \"\n",
    "    \"You'll need to comment on the kill event, using 3 senteces max. Try to also remember previous events and if you see some patterns feel free to voice them. Understood?\",\n",
    "\n",
    "    *(json.dumps(kill) for kill in kills)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg=0.60sec, min=0.59sec, max=0.60sec\n",
      "avg=0.71sec, min=0.30sec, max=1.39sec\n",
      "avg=0.78sec, min=0.52sec, max=1.24sec\n",
      "avg=0.75sec, min=0.60sec, max=0.95sec\n",
      "avg=0.87sec, min=0.30sec, max=1.33sec\n",
      "avg=0.74sec, min=0.52sec, max=1.02sec\n",
      "avg=0.93sec, min=0.60sec, max=1.54sec\n",
      "avg=1.21sec, min=0.78sec, max=1.94sec\n",
      "avg=0.81sec, min=0.52sec, max=1.57sec\n",
      "avg=0.81sec, min=0.16sec, max=2.28sec\n",
      "avg=0.78sec, min=0.35sec, max=1.67sec\n",
      "avg=0.78sec, min=0.30sec, max=2.42sec\n",
      "avg=0.76sec, min=0.30sec, max=2.06sec\n",
      "avg=0.74sec, min=0.30sec, max=2.09sec\n",
      "avg=0.71sec, min=0.23sec, max=2.33sec\n",
      "avg=0.72sec, min=0.23sec, max=2.30sec\n",
      "avg=0.81sec, min=0.23sec, max=2.61sec\n",
      "avg=0.96sec, min=0.31sec, max=2.44sec\n",
      "avg=0.88sec, min=0.46sec, max=2.85sec\n",
      "avg=0.99sec, min=0.23sec, max=3.01sec\n",
      "avg=1.14sec, min=0.31sec, max=3.49sec\n",
      "avg=1.06sec, min=0.39sec, max=3.29sec\n",
      "avg=0.96sec, min=0.15sec, max=3.52sec\n",
      "avg=1.00sec, min=0.23sec, max=3.74sec\n",
      "avg=0.94sec, min=0.23sec, max=3.69sec\n",
      "avg=1.13sec, min=0.27sec, max=4.87sec\n",
      "avg=1.08sec, min=0.16sec, max=4.13sec\n",
      "avg=0.96sec, min=0.23sec, max=4.27sec\n",
      "avg=0.83sec, min=0.16sec, max=4.50sec\n",
      "avg=1.08sec, min=0.17sec, max=4.66sec\n",
      "avg=0.91sec, min=0.08sec, max=4.87sec\n",
      "avg=0.95sec, min=0.16sec, max=4.87sec\n",
      "avg=0.99sec, min=0.24sec, max=4.98sec\n",
      "avg=0.98sec, min=0.16sec, max=5.32sec\n",
      "avg=0.94sec, min=0.16sec, max=5.29sec\n",
      "avg=0.98sec, min=0.16sec, max=5.40sec\n",
      "avg=0.95sec, min=0.08sec, max=5.58sec\n",
      "avg=1.10sec, min=0.08sec, max=5.73sec\n",
      "avg=1.02sec, min=0.08sec, max=6.08sec\n",
      "avg=1.14sec, min=0.16sec, max=6.63sec\n",
      "avg=1.08sec, min=0.08sec, max=6.43sec\n",
      "avg=1.03sec, min=0.08sec, max=6.39sec\n",
      "avg=1.06sec, min=0.09sec, max=6.71sec\n",
      "avg=1.11sec, min=0.03sec, max=6.98sec\n",
      "avg=1.12sec, min=0.08sec, max=7.12sec\n",
      "avg=1.11sec, min=0.08sec, max=7.12sec\n",
      "avg=1.04sec, min=0.08sec, max=7.27sec\n",
      "avg=1.03sec, min=0.08sec, max=7.42sec\n",
      "avg=1.19sec, min=0.08sec, max=7.67sec\n",
      "avg=1.23sec, min=0.08sec, max=7.84sec\n",
      "avg=1.22sec, min=0.08sec, max=7.98sec\n",
      "avg=1.26sec, min=0.08sec, max=8.03sec\n",
      "avg=1.25sec, min=0.08sec, max=8.12sec\n",
      "avg=1.28sec, min=0.08sec, max=8.33sec\n",
      "avg=1.16sec, min=0.08sec, max=8.39sec\n",
      "avg=1.17sec, min=0.08sec, max=8.62sec\n",
      "avg=1.34sec, min=0.08sec, max=8.69sec\n",
      "avg=1.21sec, min=0.09sec, max=8.93sec\n",
      "avg=1.23sec, min=0.08sec, max=9.18sec\n",
      "avg=1.24sec, min=0.09sec, max=9.26sec\n",
      "avg=1.48sec, min=0.08sec, max=9.74sec\n",
      "avg=1.45sec, min=0.09sec, max=9.63sec\n",
      "avg=1.48sec, min=0.09sec, max=9.95sec\n",
      "avg=1.51sec, min=0.09sec, max=10.02sec\n",
      "avg=1.51sec, min=0.09sec, max=10.18sec\n",
      "avg=1.38sec, min=0.08sec, max=10.32sec\n",
      "avg=1.38sec, min=0.08sec, max=10.47sec\n",
      "avg=1.45sec, min=0.08sec, max=10.61sec\n",
      "avg=1.62sec, min=0.17sec, max=10.97sec\n",
      "avg=1.60sec, min=0.09sec, max=10.91sec\n",
      "avg=1.62sec, min=0.09sec, max=11.19sec\n",
      "avg=1.66sec, min=0.09sec, max=11.29sec\n",
      "avg=1.49sec, min=0.09sec, max=11.38sec\n",
      "avg=1.69sec, min=0.09sec, max=11.64sec\n",
      "avg=1.70sec, min=0.09sec, max=11.73sec\n",
      "avg=1.72sec, min=0.09sec, max=11.84sec\n",
      "avg=1.74sec, min=0.09sec, max=12.00sec\n",
      "avg=1.75sec, min=0.09sec, max=12.13sec\n",
      "avg=1.62sec, min=0.09sec, max=12.54sec\n",
      "avg=1.59sec, min=0.09sec, max=12.40sec\n",
      "avg=1.87sec, min=0.17sec, max=12.89sec\n",
      "avg=1.87sec, min=0.09sec, max=13.09sec\n",
      "avg=1.88sec, min=0.09sec, max=13.09sec\n",
      "avg=1.72sec, min=0.09sec, max=13.45sec\n",
      "avg=1.70sec, min=0.17sec, max=13.26sec\n",
      "avg=1.92sec, min=0.09sec, max=13.39sec\n",
      "avg=2.02sec, min=0.09sec, max=14.21sec\n",
      "avg=1.83sec, min=0.09sec, max=14.39sec\n",
      "avg=2.08sec, min=0.09sec, max=14.81sec\n",
      "avg=2.08sec, min=0.09sec, max=14.84sec\n",
      "avg=2.11sec, min=0.09sec, max=14.90sec\n",
      "avg=2.14sec, min=0.09sec, max=15.24sec\n",
      "avg=2.17sec, min=0.08sec, max=15.39sec\n",
      "avg=2.17sec, min=0.09sec, max=15.41sec\n",
      "avg=2.16sec, min=0.09sec, max=15.18sec\n",
      "avg=2.19sec, min=0.09sec, max=15.63sec\n",
      "avg=2.00sec, min=0.09sec, max=15.66sec\n",
      "avg=2.70sec, min=0.18sec, max=15.84sec\n",
      "avg=2.02sec, min=0.09sec, max=16.07sec\n",
      "avg=2.02sec, min=0.09sec, max=16.19sec\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "for prompt in prompts[:100]:\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    )\n",
    "    response = aws.get_streamed_response_claude(messages, time.time())\n",
    "    with open(\"dialogue.txt\", \"a\") as file:\n",
    "        file.write(f\"User: {prompt}\\nAssistant: {response}\\n\")\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": response}],\n",
    "        }\n",
    "    )\n",
    "    print(aws.get_bedrock_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas\n",
    "\n",
    "things to add to init prompt:\n",
    "- total number of players\n",
    "\n",
    "things to add to kill event:\n",
    "- num players alive (useful for battle royale)\n",
    "- num kills by player\n",
    "- previous victims usernames\n",
    "- location on the map (in words, not coordinates)\n",
    "- current top 5 players by kill count\n",
    "\n",
    "for the silence moments:\n",
    " - we can send to unreal phrases where first 3 sentences are important and the rest is not so. \n",
    " This way they can use the end of the phrase while waiting for the next one\n",
    " - we can also send events with game stats and ask to comment on them\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
